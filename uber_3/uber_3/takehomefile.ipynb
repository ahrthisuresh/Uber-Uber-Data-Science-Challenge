{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahrthisuresh/Uber-Uber-Data-Science-Challenge/blob/main/uber_3/uber_3/takehomefile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bded41b6",
      "metadata": {
        "id": "bded41b6"
      },
      "source": [
        "![logo.png](https://github.com/interviewquery/takehomes/blob/origin/uber_3/uber_3/logo.png?raw=1)\n",
        "\n",
        "\n",
        "## Part 1 - SQL Syntax\n",
        "\n",
        "Given the below subset of Uber's schema, write executable SQL queries to answer the questions below. Please answer in a single query for each question and assume read-only access to the database (i.e. do not use CREATE TABLE).\n",
        "\n",
        "1. For each of the cities 'Qarth' and 'Meereen', calculate 90 th percentile difference between Actual and Predicted ETA for all completed trips within the last 30 days.\n",
        "\n",
        "2. A signup is defined as an event labeled `sign_up_success` within the `events` table. For each city ('Qarth' and 'Meereen') and each day of the week, determine the percentage of signups in the first week of 2016 that resulted in completed a trip within 168 hours of the sign up date.\n",
        "\n",
        "**Assume a PostgreSQL database, server timezone is UTC.**\n",
        "\n",
        "\n",
        "Table Name: **`trips`**\n",
        "\n",
        "|Column Name:|Datatype:|\n",
        "| :-: | :-: |\n",
        "|`id`|`integer`|\n",
        "|`client_id`|`integer` (Foreign keyed to `events.rider_id`)|\n",
        "|`driver_id`|`integer`|\n",
        "|`city_id`|`integer` (Foreign keyed to `cities.city_id`)|\n",
        "|`client_rating`|`integer`|\n",
        "|`driver_rating`|`integer`|\n",
        "|`request_at`|`Timestamp with timezone`|\n",
        "|`predicted_eta`|`integer`|\n",
        "|`actual_eta`|`integer`|\n",
        "|`status`|`Enum`(‘`completed`’, ‘`cancelled_by_driver`’, ‘`cancelled_by_client`’)|\n",
        "\n",
        "\n",
        "Table Name: **`cities`**\n",
        "\n",
        "|Column Name:|Datatype:|\n",
        "| :-: | :-: |\n",
        "|`city_id`|`integer`|\n",
        "|`city_name`|`string`|\n",
        "\n",
        "\n",
        "\n",
        "Table Name: **`events`**\n",
        "\n",
        "|Column Name:|Datatype:|\n",
        "| :-: | :-: |\n",
        "|`device_id`|`integer`|\n",
        "|`rider_id`|`integer`|\n",
        "|`city_id`|`integer`|\n",
        "|`event_name`|`Enum`(‘`sign_up_success`’, ‘`attempted_sign_up`’, ‘`sign_up_failure`’)|\n",
        "\n",
        "\n",
        "\n",
        "## Part 2 - Experiment and metrics design\n",
        "\n",
        "\n",
        "The Driver Experience team has just finished [redesigning the Uber Partner app](https://newsroom.uber.com/new-partner-app/). The new version expands the purpose of the app beyond just driving. It includes additional information on earnings, ratings, and provides a unified platform for Uber to communicate with its partners.\n",
        "\n",
        "1. Propose and define the primary success metric of the redesigned app. What are 2-3 additional tracking metrics that will be important to monitor in addition to the success metric defined above?\n",
        "\n",
        "2. Outline a testing plan to evaluate if redesigned app performs better (according to the metrics you outlined). How would you balance the need to deliver quick results, with statistical rigor, and while still monitoring for risks?\n",
        "\n",
        "3. Explain how you would translate the results from the testing plan into a decision on whether to launch the new design or roll it back.\n",
        "\n",
        "## Part 3 - Data analysis\n",
        "\n",
        "Uber's Driver team is interested in predicting which driver signups are most likely to start driving. To help explore this question, we have provided a sample  dataset of a cohort of driver signups in January 2015.The data was pulled a few months after they signed up to include the result of whether they actually completed their first trip. It also includes several pieces of background information gather about the driver and their car.\n",
        "\n",
        "We would like you to use this data set to help understand what factors are best at predicting whether a signup will start to drive, and offer suggestions to operationalize those insights to help Uber.\n",
        "\n",
        "See below for a detailed description of the dataset. Please include any code you wrote for the analysis and delete the dataset when you have finished with the challenge. Please also call out any data related assumptions or issues that you encounter.\n",
        "\n",
        "1. Perform any cleaning, exploratory analysis, and/or visualizations to use the provided data for this analysis (a few sentences/plots describing your approach will suffice). What fraction of the driver signups took a first trip?\n",
        "\n",
        "2. Build a predictive model to help Uber determine whether or not a driver signup will start driving. Discuss why you chose your approach, what alternatives you considered, and any concerns you have. How valid is your model? Include any key indicators of model performance.\n",
        "\n",
        "3. Briefly discuss how Uber might leverage the insights gained from the model to generate more first trips (again, a few ideas/sentences will suffice).\n",
        "\n",
        "\n",
        "\n",
        "### Data description\n",
        "\n",
        "**id**: driver_id\n",
        "\n",
        "**city_id**: city_id this user signed up in\n",
        "\n",
        "**signup_os**: signup device of the user (\"android\", \"ios\", \"website\", \"other\")\n",
        "\n",
        "**signup_channel**: what channel did the driver sign up from (\"offline\", \"paid\", \"organic\", \"referral\")\n",
        "\n",
        "**signup_timestamp**: timestamp of account creation; local time in the form 'YYYY/MM/DD'\n",
        "\n",
        "**bgc_date**: date of background check consent; in the form 'YYYY/MM/DD'\n",
        "\n",
        "**vehicle_added_date**: date when driver's vehicle information was uploaded; in the form 'YYYY/MM/DD'\n",
        "\n",
        "**first_trip_date**: date of the first trip as a driver; in the form 'YYYY/MM/DD'\n",
        "\n",
        "**vehicle_make**: make of vehicle uploaded (i.e. Honda, Ford, Kia)\n",
        "\n",
        "**vehicle_model**: model of vehicle uploaded (i.e. Accord, Prius, 350z)\n",
        "\n",
        "**vehicle year**: year that the car was made; in the form 'YYYY'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Please note that this data is fake and does not represent actual driver signup behavior\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5c956dc4",
      "metadata": {
        "id": "5c956dc4",
        "outputId": "e5f33e43-a2c2-44d5-a24c-3bf93e2ff0be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'takehomes'...\n",
            "remote: Enumerating objects: 1963, done.\u001b[K\n",
            "remote: Counting objects: 100% (1963/1963), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1220/1220), done.\u001b[K\n",
            "remote: Total 1963 (delta 752), reused 1928 (delta 726), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (1963/1963), 297.43 MiB | 13.41 MiB/s, done.\n",
            "Resolving deltas: 100% (752/752), done.\n",
            "/content/takehomes/uber_3\n",
            "ls: cannot access '*.zip': No such file or directory\n",
            "ds_challenge_v2_1_data.csv  logo.png  takehomefile.ipynb\n"
          ]
        }
      ],
      "source": [
        "!git clone --branch origin/uber_3 https://github.com/interviewquery/takehomes.git\n",
        "%cd takehomes/uber_3\n",
        "!if [[ $(ls *.zip) ]]; then unzip *.zip; fi\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "53d25f14",
      "metadata": {
        "id": "53d25f14",
        "outputId": "d023bbd4-2297-410f-9f81-31890712b171",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "DatabaseError",
          "evalue": "Execution failed on sql '\nSelect city_name, Percentile_cont(0.90) within group (order by actual_eta - predicted_eta) as eta_diff_90th_percentile\nFrom data\nwhere status = 'completed'\nand request_at >= now() - interval '30 days'\nand c.city_name in ('Qarth','Meereen')\ngroup by c.city_name;\n\n': near \"(\": syntax error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2673\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2674\u001b[0;31m             \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2675\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOperationalError\u001b[0m: near \"(\": syntax error",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-ddb01a1120f7>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \"\"\"\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mresult_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mpandasSQL_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpandas_sql\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         return pandas_sql.read_query(\n\u001b[0m\u001b[1;32m    527\u001b[0m             \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   2736\u001b[0m         \u001b[0mdtype_backend\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDtypeBackend\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2737\u001b[0m     ) -> DataFrame | Iterator[DataFrame]:\n\u001b[0;32m-> 2738\u001b[0;31m         \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2739\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol_desc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_desc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2685\u001b[0m             \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatabaseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Execution failed on sql '{sql}': {exc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2686\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2688\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql '\nSelect city_name, Percentile_cont(0.90) within group (order by actual_eta - predicted_eta) as eta_diff_90th_percentile\nFrom data\nwhere status = 'completed'\nand request_at >= now() - interval '30 days'\nand c.city_name in ('Qarth','Meereen')\ngroup by c.city_name;\n\n': near \"(\": syntax error"
          ]
        }
      ],
      "source": [
        "from posixpath import join\n",
        "import pandas as pd\n",
        "# Write your code here\n",
        "\n",
        "df = pd.read_csv('/content/takehomes/uber_3/ds_challenge_v2_1_data.csv')\n",
        "# Step 4: Create an SQLite database and load DataFrames\n",
        "import sqlite3\n",
        "\n",
        "# Create a new SQLite database (in-memory)\n",
        "conn = sqlite3.connect(':memory:')\n",
        "df.to_sql('data',conn,index=False , if_exists='replace')\n",
        "# Write DataFrames to the database\n",
        "\n",
        "#PART A\n",
        "query_1 = \"\"\"\n",
        "Select city_name, Percentile_cont(0.90) within group (order by actual_eta - predicted_eta) as eta_diff_90th_percentile\n",
        "From data\n",
        "where status = 'completed'\n",
        "and request_at >= now() - interval '30 days'\n",
        "and city_name in ('Qarth','Meereen')\n",
        "group by city_name;\n",
        "\n",
        "\"\"\"\n",
        "result_1 = pd.read_sql_query(query_1, conn)\n",
        "print(result_1)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}